{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac6b7d53-d4e8-4136-9066-c310a3aa325c",
   "metadata": {},
   "source": [
    "# Comparative Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46bd67f-7250-4398-a7c6-3bd532f54d84",
   "metadata": {},
   "source": [
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad7d70eb-ee51-4132-962c-b0b3a7b29d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder,\n",
    "    LabelEncoder, SplineTransformer, OrdinalEncoder\n",
    ")\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_validate, ShuffleSplit\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d1eb45-8226-458f-ad7e-49b09fd19aff",
   "metadata": {},
   "source": [
    "## Tratamento dos Dados\n",
    "\n",
    "#### Como nosso objetivo é predizer a precipitação mensal para as Regiões Hidrográficas do Estado do Ceará, precisamos que nosso modelo consiga fazer a predição da precipitação futura. <br><br> Para tal, foi criada uma função que cria uma janela e para cada ponto (lat,lon), adiciona a respectiva precipitação 2 meses à frente.  <br><br>  Além disso, avaliamos a influência das variáveis preditoras (índices oceânicos e variáveis atmosféricas) nos 4 meses anteriores, a fim de buscar a melhor forma de predição. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01f17964-02cc-4bd0-aa90-fcb008e8b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_future(df, columns, janela):\n",
    "    \"\"\"\n",
    "    A função pega a base de dados, e para cada ponto (lat,lon), adiciona a respectiva precipitação 2 meses à frente e algumas variáveis nos últimos 4 meses\n",
    "    \n",
    "    \"\"\"\n",
    "    suffix = 'mais' if janela > 0 else 'menos'\n",
    "    df_out = df.copy()\n",
    "    new_columns = [f'{variavel}_{suffix}_{abs(janela)}' for variavel in columns]\n",
    "    for posicao in df.posicao.unique():\n",
    "        criteria = \"posicao == @posicao\"\n",
    "        df_out.loc[df_out.eval(criteria), new_columns] = (\n",
    "            df_out\n",
    "            .query(criteria)\n",
    "            .shift(periods=-janela)[columns].values\n",
    "        )\n",
    "    return df_out\n",
    "\n",
    "important_columns = [\n",
    "    #'divergencia', 'umidade', 'vento_vertical', 'vorticidade', 'fluxo_energia', \n",
    "    'EMI', 'nino3', 'atl3' #, 'atn', 'ats', 'atlgrad',  'seta', 'nesta'\n",
    "]\n",
    "df_original = (\n",
    "    pd\n",
    "    .read_csv(\"../data/raw/data_regiao_hidro.csv\")\n",
    "    .pipe(get_future, ['pr'], 2)\n",
    "    .pipe(get_future, important_columns, -1)\n",
    "    .pipe(get_future, important_columns, -2)\n",
    "    .pipe(get_future, important_columns, -3)\n",
    "    .pipe(get_future, important_columns, -4)\n",
    "    .sample(1000, random_state=42) #remover depois\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49f22ce8-af43-4a3b-a835-6566863b06cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_original.assign(\n",
    "    lat = df_original.posicao.apply(lambda x: eval(x)[0]),\n",
    "    lon = df_original.posicao.apply(lambda x: eval(x)[1]),\n",
    "    ano = df_original.data.apply(lambda x: int(x[:4])),\n",
    "    mes = df_original.data.apply(lambda x: int(x[5:7]))\n",
    ").drop(columns=[\"data\",\"posicao\",\"regiao_hidro\"], axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d135bb05-1751-4213-b93d-c1f10f7102b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pr</th>\n",
       "      <th>divergencia</th>\n",
       "      <th>umidade</th>\n",
       "      <th>vento_vertical</th>\n",
       "      <th>vorticidade</th>\n",
       "      <th>fluxo_energia</th>\n",
       "      <th>EMI</th>\n",
       "      <th>nino3</th>\n",
       "      <th>atn</th>\n",
       "      <th>ats</th>\n",
       "      <th>...</th>\n",
       "      <th>EMI_menos_3</th>\n",
       "      <th>nino3_menos_3</th>\n",
       "      <th>atl3_menos_3</th>\n",
       "      <th>EMI_menos_4</th>\n",
       "      <th>nino3_menos_4</th>\n",
       "      <th>atl3_menos_4</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>ano</th>\n",
       "      <th>mes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51892</th>\n",
       "      <td>266.61</td>\n",
       "      <td>-2.170750e-07</td>\n",
       "      <td>88.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>185.95</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>0.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.25</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>-41.00</td>\n",
       "      <td>2003</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56734</th>\n",
       "      <td>289.18</td>\n",
       "      <td>3.376360e-06</td>\n",
       "      <td>81.33</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>10.95</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-5.75</td>\n",
       "      <td>-40.50</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62896</th>\n",
       "      <td>4.05</td>\n",
       "      <td>-2.306960e-08</td>\n",
       "      <td>63.55</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>72.78</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-1.61</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-1.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>-39.00</td>\n",
       "      <td>2007</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15323</th>\n",
       "      <td>19.93</td>\n",
       "      <td>2.969190e-06</td>\n",
       "      <td>73.13</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>67.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>-41.00</td>\n",
       "      <td>1987</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81862</th>\n",
       "      <td>9.36</td>\n",
       "      <td>4.516920e-06</td>\n",
       "      <td>67.78</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>51.28</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2.47</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2.05</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-5.75</td>\n",
       "      <td>-39.00</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10078</th>\n",
       "      <td>255.55</td>\n",
       "      <td>5.928090e-06</td>\n",
       "      <td>91.19</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-57.31</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>0.23</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>0.48</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>-39.50</td>\n",
       "      <td>1985</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39010</th>\n",
       "      <td>3.68</td>\n",
       "      <td>-1.399030e-06</td>\n",
       "      <td>56.23</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>1.80</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>2.80</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>1.60</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>-38.50</td>\n",
       "      <td>1997</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79307</th>\n",
       "      <td>3.89</td>\n",
       "      <td>-4.737290e-06</td>\n",
       "      <td>68.78</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-115.34</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.77</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>-39.25</td>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88069</th>\n",
       "      <td>1.70</td>\n",
       "      <td>-5.498480e-06</td>\n",
       "      <td>67.76</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>148.34</td>\n",
       "      <td>0.67</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>-40.50</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2547</th>\n",
       "      <td>140.76</td>\n",
       "      <td>4.830790e-06</td>\n",
       "      <td>80.14</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>101.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.78</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>-38.75</td>\n",
       "      <td>1982</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pr   divergencia  umidade  vento_vertical  vorticidade  \\\n",
       "51892  266.61 -2.170750e-07    88.00            0.30    -0.000003   \n",
       "56734  289.18  3.376360e-06    81.33           -0.19     0.000007   \n",
       "62896    4.05 -2.306960e-08    63.55           -0.08     0.000010   \n",
       "15323   19.93  2.969190e-06    73.13            0.31     0.000014   \n",
       "81862    9.36  4.516920e-06    67.78           -0.15     0.000026   \n",
       "...       ...           ...      ...             ...          ...   \n",
       "10078  255.55  5.928090e-06    91.19           -0.08     0.000007   \n",
       "39010    3.68 -1.399030e-06    56.23            0.01     0.000017   \n",
       "79307    3.89 -4.737290e-06    68.78           -0.05     0.000016   \n",
       "88069    1.70 -5.498480e-06    67.76           -0.04     0.000013   \n",
       "2547   140.76  4.830790e-06    80.14           -0.04     0.000018   \n",
       "\n",
       "       fluxo_energia   EMI  nino3   atn   ats  ...  EMI_menos_3  \\\n",
       "51892         185.95  0.92   0.25 -0.26  0.34  ...         0.36   \n",
       "56734          10.95  0.81   0.04  0.75  0.14  ...         0.84   \n",
       "62896          72.78 -0.50  -1.61 -0.19  0.01  ...         0.08   \n",
       "15323          67.04  0.08   1.36  0.52  0.39  ...        -0.23   \n",
       "81862          51.28  0.36   2.81  0.13  0.33  ...         0.03   \n",
       "...              ...   ...    ...   ...   ...  ...          ...   \n",
       "10078         -57.31 -0.86  -0.72 -0.66  0.23  ...        -0.25   \n",
       "39010           1.80 -0.68   2.80 -0.04 -0.20  ...        -0.47   \n",
       "79307        -115.34  0.66   0.77 -0.05 -0.37  ...         0.11   \n",
       "88069         148.34  0.67  -0.06 -0.09  0.33  ...         0.27   \n",
       "2547          101.80  0.00   0.12  0.02 -0.04  ...        -0.01   \n",
       "\n",
       "       nino3_menos_3  atl3_menos_3  EMI_menos_4  nino3_menos_4  atl3_menos_4  \\\n",
       "51892           1.14          0.38         0.24           1.25         -0.02   \n",
       "56734           0.65          0.16         0.80           0.59          0.23   \n",
       "62896          -1.15          0.05         0.09          -0.92          0.27   \n",
       "15323           0.97          0.14         0.16           1.13          0.22   \n",
       "81862           2.47         -0.13         0.19           2.05         -0.39   \n",
       "...              ...           ...          ...            ...           ...   \n",
       "10078          -1.18          0.26        -0.58          -1.09          0.48   \n",
       "39010           1.60         -1.17         0.25           0.73         -0.54   \n",
       "79307           0.17         -0.32         0.03           0.28         -0.48   \n",
       "88069          -0.35          0.32         0.21          -0.64          0.01   \n",
       "2547           -0.16          0.78        -0.07           0.04          0.90   \n",
       "\n",
       "        lat    lon   ano  mes  \n",
       "51892 -4.25 -41.00  2003    3  \n",
       "56734 -5.75 -40.50  2005    3  \n",
       "62896 -5.00 -39.00  2007   11  \n",
       "15323 -3.75 -41.00  1987    7  \n",
       "81862 -5.75 -39.00  2015   12  \n",
       "...     ...    ...   ...  ...  \n",
       "10078 -4.00 -39.50  1985    4  \n",
       "39010 -4.25 -38.50  1997    9  \n",
       "79307 -3.75 -39.25  2014   11  \n",
       "88069 -3.00 -40.50  2018    8  \n",
       "2547  -4.00 -38.75  1982    2  \n",
       "\n",
       "[989 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4e2f27d-fbeb-43b9-9b09-43ba43e94f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pr                0\n",
       "nino3_menos_1     0\n",
       "ano               0\n",
       "lon               0\n",
       "lat               0\n",
       "atl3_menos_4      0\n",
       "nino3_menos_4     0\n",
       "EMI_menos_4       0\n",
       "atl3_menos_3      0\n",
       "nino3_menos_3     0\n",
       "EMI_menos_3       0\n",
       "atl3_menos_2      0\n",
       "nino3_menos_2     0\n",
       "EMI_menos_2       0\n",
       "atl3_menos_1      0\n",
       "EMI_menos_1       0\n",
       "divergencia       0\n",
       "pr_mais_2         0\n",
       "nesta             0\n",
       "seta              0\n",
       "atl3              0\n",
       "atlgrad           0\n",
       "ats               0\n",
       "atn               0\n",
       "nino3             0\n",
       "EMI               0\n",
       "fluxo_energia     0\n",
       "vorticidade       0\n",
       "vento_vertical    0\n",
       "umidade           0\n",
       "mes               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abd9647e-ec9f-4a83-b9d9-23126354cbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['range_pr'] = pd.cut(df.pr_mais_2, bins=[0,50,100,200,300,400,800], labels=['0 a 50','50.1 a 100','100.1 a 200','200.1 a 300','300.1 a 400','Acima de 400'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6395675-1d5d-4b03-b9cf-800d07004da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0 a 50          612\n",
       "50.1 a 100      131\n",
       "100.1 a 200     161\n",
       "200.1 a 300      56\n",
       "300.1 a 400      23\n",
       "Acima de 400      6\n",
       "Name: range_pr, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['range_pr'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b51dbabb-1241-4cd5-8265-951ac7fdb483",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'range_pr'\n",
    "#nominal_columns = [column for column in list(df.select_dtypes(object)) if column != target_column]\n",
    "quantitative_columns = [column for column in list(df.select_dtypes(np.number)) if column != 'pr_mais_2'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0d63df4-581f-4a7a-a9ce-96721e74450d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (\n",
    "    df\n",
    "    .query(f'{target_column}.notna()')\n",
    "    .drop([target_column,'pr_mais_2'], axis=1)\n",
    ")\n",
    "target_transformer = LabelEncoder()\n",
    "y = target_transformer.fit_transform(\n",
    "    df\n",
    "    .query(f'{target_column}.notna()')[[target_column]]\n",
    "    .values.ravel()\n",
    ")#[np.newaxis].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f468e99b-cc0e-4635-9f33-0551d95ad468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(989, 30)\n",
      "(989,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d6deb6b-70e9-42d3-a4ac-488ea5583682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pr</th>\n",
       "      <th>divergencia</th>\n",
       "      <th>umidade</th>\n",
       "      <th>vento_vertical</th>\n",
       "      <th>vorticidade</th>\n",
       "      <th>fluxo_energia</th>\n",
       "      <th>EMI</th>\n",
       "      <th>nino3</th>\n",
       "      <th>atn</th>\n",
       "      <th>ats</th>\n",
       "      <th>...</th>\n",
       "      <th>EMI_menos_3</th>\n",
       "      <th>nino3_menos_3</th>\n",
       "      <th>atl3_menos_3</th>\n",
       "      <th>EMI_menos_4</th>\n",
       "      <th>nino3_menos_4</th>\n",
       "      <th>atl3_menos_4</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>ano</th>\n",
       "      <th>mes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51892</th>\n",
       "      <td>266.61</td>\n",
       "      <td>-2.170750e-07</td>\n",
       "      <td>88.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>185.95</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>0.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.25</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>-41.00</td>\n",
       "      <td>2003</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56734</th>\n",
       "      <td>289.18</td>\n",
       "      <td>3.376360e-06</td>\n",
       "      <td>81.33</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>10.95</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-5.75</td>\n",
       "      <td>-40.50</td>\n",
       "      <td>2005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62896</th>\n",
       "      <td>4.05</td>\n",
       "      <td>-2.306960e-08</td>\n",
       "      <td>63.55</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>72.78</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-1.61</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-1.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>-39.00</td>\n",
       "      <td>2007</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15323</th>\n",
       "      <td>19.93</td>\n",
       "      <td>2.969190e-06</td>\n",
       "      <td>73.13</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>67.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>-41.00</td>\n",
       "      <td>1987</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81862</th>\n",
       "      <td>9.36</td>\n",
       "      <td>4.516920e-06</td>\n",
       "      <td>67.78</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>51.28</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2.47</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2.05</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>-5.75</td>\n",
       "      <td>-39.00</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10078</th>\n",
       "      <td>255.55</td>\n",
       "      <td>5.928090e-06</td>\n",
       "      <td>91.19</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-57.31</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.66</td>\n",
       "      <td>0.23</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-1.18</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>-1.09</td>\n",
       "      <td>0.48</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>-39.50</td>\n",
       "      <td>1985</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39010</th>\n",
       "      <td>3.68</td>\n",
       "      <td>-1.399030e-06</td>\n",
       "      <td>56.23</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>1.80</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>2.80</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>1.60</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>-38.50</td>\n",
       "      <td>1997</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79307</th>\n",
       "      <td>3.89</td>\n",
       "      <td>-4.737290e-06</td>\n",
       "      <td>68.78</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-115.34</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.77</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>-39.25</td>\n",
       "      <td>2014</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88069</th>\n",
       "      <td>1.70</td>\n",
       "      <td>-5.498480e-06</td>\n",
       "      <td>67.76</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>148.34</td>\n",
       "      <td>0.67</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.27</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.21</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-3.00</td>\n",
       "      <td>-40.50</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2547</th>\n",
       "      <td>140.76</td>\n",
       "      <td>4.830790e-06</td>\n",
       "      <td>80.14</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>101.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>0.78</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-4.00</td>\n",
       "      <td>-38.75</td>\n",
       "      <td>1982</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pr   divergencia  umidade  vento_vertical  vorticidade  \\\n",
       "51892  266.61 -2.170750e-07    88.00            0.30    -0.000003   \n",
       "56734  289.18  3.376360e-06    81.33           -0.19     0.000007   \n",
       "62896    4.05 -2.306960e-08    63.55           -0.08     0.000010   \n",
       "15323   19.93  2.969190e-06    73.13            0.31     0.000014   \n",
       "81862    9.36  4.516920e-06    67.78           -0.15     0.000026   \n",
       "...       ...           ...      ...             ...          ...   \n",
       "10078  255.55  5.928090e-06    91.19           -0.08     0.000007   \n",
       "39010    3.68 -1.399030e-06    56.23            0.01     0.000017   \n",
       "79307    3.89 -4.737290e-06    68.78           -0.05     0.000016   \n",
       "88069    1.70 -5.498480e-06    67.76           -0.04     0.000013   \n",
       "2547   140.76  4.830790e-06    80.14           -0.04     0.000018   \n",
       "\n",
       "       fluxo_energia   EMI  nino3   atn   ats  ...  EMI_menos_3  \\\n",
       "51892         185.95  0.92   0.25 -0.26  0.34  ...         0.36   \n",
       "56734          10.95  0.81   0.04  0.75  0.14  ...         0.84   \n",
       "62896          72.78 -0.50  -1.61 -0.19  0.01  ...         0.08   \n",
       "15323          67.04  0.08   1.36  0.52  0.39  ...        -0.23   \n",
       "81862          51.28  0.36   2.81  0.13  0.33  ...         0.03   \n",
       "...              ...   ...    ...   ...   ...  ...          ...   \n",
       "10078         -57.31 -0.86  -0.72 -0.66  0.23  ...        -0.25   \n",
       "39010           1.80 -0.68   2.80 -0.04 -0.20  ...        -0.47   \n",
       "79307        -115.34  0.66   0.77 -0.05 -0.37  ...         0.11   \n",
       "88069         148.34  0.67  -0.06 -0.09  0.33  ...         0.27   \n",
       "2547          101.80  0.00   0.12  0.02 -0.04  ...        -0.01   \n",
       "\n",
       "       nino3_menos_3  atl3_menos_3  EMI_menos_4  nino3_menos_4  atl3_menos_4  \\\n",
       "51892           1.14          0.38         0.24           1.25         -0.02   \n",
       "56734           0.65          0.16         0.80           0.59          0.23   \n",
       "62896          -1.15          0.05         0.09          -0.92          0.27   \n",
       "15323           0.97          0.14         0.16           1.13          0.22   \n",
       "81862           2.47         -0.13         0.19           2.05         -0.39   \n",
       "...              ...           ...          ...            ...           ...   \n",
       "10078          -1.18          0.26        -0.58          -1.09          0.48   \n",
       "39010           1.60         -1.17         0.25           0.73         -0.54   \n",
       "79307           0.17         -0.32         0.03           0.28         -0.48   \n",
       "88069          -0.35          0.32         0.21          -0.64          0.01   \n",
       "2547           -0.16          0.78        -0.07           0.04          0.90   \n",
       "\n",
       "        lat    lon   ano  mes  \n",
       "51892 -4.25 -41.00  2003    3  \n",
       "56734 -5.75 -40.50  2005    3  \n",
       "62896 -5.00 -39.00  2007   11  \n",
       "15323 -3.75 -41.00  1987    7  \n",
       "81862 -5.75 -39.00  2015   12  \n",
       "...     ...    ...   ...  ...  \n",
       "10078 -4.00 -39.50  1985    4  \n",
       "39010 -4.25 -38.50  1997    9  \n",
       "79307 -3.75 -39.25  2014   11  \n",
       "88069 -3.00 -40.50  2018    8  \n",
       "2547  -4.00 -38.75  1982    2  \n",
       "\n",
       "[989 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dd2d5fd-f411-4fdd-bf64-623c44a4a8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nominal_preprocessing = Pipeline([    \n",
    "#     (\"missing\", SimpleImputer(strategy='most_frequent')),\n",
    "#     (\"encoder\", OneHotEncoder(sparse=False)),\n",
    "#     (\"scaler\", StandardScaler())\n",
    "# ])\n",
    "quantitative_preprocessing = Pipeline([\n",
    "    (\"missing\", SimpleImputer()),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "preprocessing = ColumnTransformer([\n",
    "    (\"ohe\", OneHotEncoder(), [\"mes\"]),\n",
    "    #(\"nominal\", nominal_preprocessing, nominal_columns),\n",
    "    (\"quantitative\", quantitative_preprocessing, quantitative_columns)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef25cfd6-2f02-437e-96bf-15dcec6d8b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [{\n",
    "    'name': 'knn',\n",
    "    'model': KNeighborsClassifier(),\n",
    "    'parameters': {\n",
    "        'n_neighbors': np.arange(3, 17, 2),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan']\n",
    "    }\n",
    "}\n",
    "    ,{\n",
    "    'name': 'LR',\n",
    "    'model': LogisticRegression(max_iter=3000, solver='saga', multi_class='ovr'),\n",
    "    'parameters': {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C' : np.logspace(-4, 4, 10),\n",
    "    }\n",
    "}\n",
    ",{\n",
    "    'name': 'SVC',\n",
    "    'model': SVC(max_iter=10000, gamma='auto'),\n",
    "    'parameters': {\n",
    "        \"C\": [1, 10, 100, 1e3]\n",
    "    }\n",
    "},\n",
    "    {\n",
    "    'name': 'GB',\n",
    "    'model': GradientBoostingClassifier(loss=\"deviance\"),\n",
    "    'parameters': {\n",
    "        \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "        \"min_samples_split\": np.linspace(0.1, 0.5, 6),\n",
    "        \"min_samples_leaf\": np.linspace(0.1, 0.5, 6),\n",
    "        \"max_depth\": [3, 5, 8],\n",
    "        \"max_features\": [\"log2\", \"sqrt\"],\n",
    "        \"criterion\": [\"friedman_mse\", \"squared_error\"],\n",
    "        \"subsample\": [0.5, 0.8, 0.9, 1.0]\n",
    "    }\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dd7e5bc-83a0-4a0a-a915-1bb38e488199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate(*args):\n",
    "    final_dict = {key: [] for key in args[0].keys()}\n",
    "    for dictionary in args:\n",
    "        for key, value in dictionary.items():\n",
    "            final_dict[key].extend(value)\n",
    "    return final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1970091-5041-41bb-92e0-1be8559b9244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running knn\n",
      "running LR\n",
      "running SVC\n",
      "running GB\n"
     ]
    }
   ],
   "source": [
    "n_splits_cv = 2\n",
    "n_splits_cv_gs = 3\n",
    "sc = []\n",
    "for model in models:\n",
    "    print(f\"running {model['name']}\")\n",
    "    param_grid = {\n",
    "        'preprocessing__quantitative__scaler': [StandardScaler(), MinMaxScaler(), RobustScaler()],\n",
    "        #'preprocessing__nominal__encoder': [OneHotEncoder(sparse=False), OrdinalEncoder()],\n",
    "        #'preprocessing__nominal__scaler': [StandardScaler(), MinMaxScaler(), RobustScaler()],\n",
    "        'preprocessing__quantitative__missing__strategy': ['mean', 'median'],\n",
    "        **{f\"model__{key}\": value for key, value in model['parameters'].items()}\n",
    "    }\n",
    "    approach = Pipeline([\n",
    "        ('preprocessing', preprocessing),\n",
    "        ('model', model['model'])\n",
    "    ])\n",
    "    gs = RandomizedSearchCV(\n",
    "        estimator=approach,\n",
    "        param_distributions=param_grid,\n",
    "        scoring='accuracy',\n",
    "        cv=n_splits_cv_gs,\n",
    "        random_state=42\n",
    "    )\n",
    "    scores = cross_validate(\n",
    "        estimator = gs,\n",
    "        X=X,\n",
    "        y=y,\n",
    "        cv = ShuffleSplit(n_splits=n_splits_cv, test_size=.2, random_state=42),\n",
    "        n_jobs = -1,\n",
    "        scoring = {\n",
    "           'accuracy': make_scorer(metrics.accuracy_score, average='weighted'),\n",
    "           'precision': make_scorer(metrics.precision_score, average='weighted'),\n",
    "           'recall': make_scorer(metrics.recall_score, average='weighted'),\n",
    "           'f1': make_scorer(metrics.f1_score, average='weighted')\n",
    "           }\n",
    "    )\n",
    "    scores['model'] = [model['name']] * n_splits_cv\n",
    "    sc.append(scores)\n",
    "scores = concatenate(*sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14d32480-e3bf-4eab-8683-39115b792063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f984c_row0_col4, #T_f984c_row1_col2, #T_f984c_row2_col1, #T_f984c_row3_col1, #T_f984c_row4_col1, #T_f984c_row5_col1 {\n",
       "  color: white;\n",
       "  background-color: gray;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f984c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_f984c_level0_col0\" class=\"col_heading level0 col0\" >score</th>\n",
       "      <th id=\"T_f984c_level0_col1\" class=\"col_heading level0 col1\" >GB</th>\n",
       "      <th id=\"T_f984c_level0_col2\" class=\"col_heading level0 col2\" >LR</th>\n",
       "      <th id=\"T_f984c_level0_col3\" class=\"col_heading level0 col3\" >SVC</th>\n",
       "      <th id=\"T_f984c_level0_col4\" class=\"col_heading level0 col4\" >knn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_f984c_row0_col0\" class=\"data row0 col0\" >fit_time</td>\n",
       "      <td id=\"T_f984c_row0_col1\" class=\"data row0 col1\" >7.865 ± 0.025</td>\n",
       "      <td id=\"T_f984c_row0_col2\" class=\"data row0 col2\" >17.645 ± 0.398</td>\n",
       "      <td id=\"T_f984c_row0_col3\" class=\"data row0 col3\" >0.712 ± 0.015</td>\n",
       "      <td id=\"T_f984c_row0_col4\" class=\"data row0 col4\" >0.466 ± 0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f984c_row1_col0\" class=\"data row1 col0\" >score_time</td>\n",
       "      <td id=\"T_f984c_row1_col1\" class=\"data row1 col1\" >0.005 ± 0.000</td>\n",
       "      <td id=\"T_f984c_row1_col2\" class=\"data row1 col2\" >0.003 ± 0.000</td>\n",
       "      <td id=\"T_f984c_row1_col3\" class=\"data row1 col3\" >0.007 ± 0.000</td>\n",
       "      <td id=\"T_f984c_row1_col4\" class=\"data row1 col4\" >0.007 ± 0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f984c_row2_col0\" class=\"data row2 col0\" >test_accuracy</td>\n",
       "      <td id=\"T_f984c_row2_col1\" class=\"data row2 col1\" >nan ± nan</td>\n",
       "      <td id=\"T_f984c_row2_col2\" class=\"data row2 col2\" >nan ± nan</td>\n",
       "      <td id=\"T_f984c_row2_col3\" class=\"data row2 col3\" >nan ± nan</td>\n",
       "      <td id=\"T_f984c_row2_col4\" class=\"data row2 col4\" >nan ± nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f984c_row3_col0\" class=\"data row3 col0\" >test_precision</td>\n",
       "      <td id=\"T_f984c_row3_col1\" class=\"data row3 col1\" >nan ± nan</td>\n",
       "      <td id=\"T_f984c_row3_col2\" class=\"data row3 col2\" >nan ± nan</td>\n",
       "      <td id=\"T_f984c_row3_col3\" class=\"data row3 col3\" >nan ± nan</td>\n",
       "      <td id=\"T_f984c_row3_col4\" class=\"data row3 col4\" >nan ± nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f984c_row4_col0\" class=\"data row4 col0\" >test_recall</td>\n",
       "      <td id=\"T_f984c_row4_col1\" class=\"data row4 col1\" >nan ± nan</td>\n",
       "      <td id=\"T_f984c_row4_col2\" class=\"data row4 col2\" >nan ± nan</td>\n",
       "      <td id=\"T_f984c_row4_col3\" class=\"data row4 col3\" >nan ± nan</td>\n",
       "      <td id=\"T_f984c_row4_col4\" class=\"data row4 col4\" >nan ± nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_f984c_row5_col0\" class=\"data row5 col0\" >test_f1</td>\n",
       "      <td id=\"T_f984c_row5_col1\" class=\"data row5 col1\" >nan ± nan</td>\n",
       "      <td id=\"T_f984c_row5_col2\" class=\"data row5 col2\" >nan ± nan</td>\n",
       "      <td id=\"T_f984c_row5_col3\" class=\"data row5 col3\" >nan ± nan</td>\n",
       "      <td id=\"T_f984c_row5_col4\" class=\"data row5 col4\" >nan ± nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f10638bf820>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O melhor modelo é o GB\n"
     ]
    }
   ],
   "source": [
    "def highlight_max(s, props=''):\n",
    "    values = [float(value.split()[0]) for value in s.values[1:]]\n",
    "    result = [''] * len(s.values)\n",
    "    if s.values[0].endswith('time'):\n",
    "        result[np.argmin(values)+1] = props\n",
    "    else:\n",
    "        result[np.argmax(values)+1] = props\n",
    "    return result\n",
    "\n",
    "def get_winner(s):\n",
    "    metric = s.values[0]\n",
    "    values = [float(value.split()[0]) for value in s.values[1:]]\n",
    "    models = results.columns[1:]\n",
    "    \n",
    "    if s.values[0].endswith('time'):\n",
    "        return models[np.argmin(values)]\n",
    "    else:\n",
    "        return models[np.argmax(values)]\n",
    "\n",
    "results = (\n",
    "    pd\n",
    "    .DataFrame(scores)\n",
    "    .groupby(['model'])\n",
    "    .agg([lambda x: f\"{np.mean(x):.3f} ± {np.std(x):.3f}\"])\n",
    "    .transpose()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"level_0\": \"score\"})\n",
    "    .drop(columns=\"level_1\")\n",
    "    # .set_index('score')\n",
    ")\n",
    "time_scores = ['fit_time', 'score_time']\n",
    "winner = results.query('score not in @time_scores').apply(get_winner, axis=1).value_counts().index[0]\n",
    "results.columns.name = ''\n",
    "results = (\n",
    "    results\n",
    "    .style\n",
    "    .hide(axis='index')\n",
    "    .apply(highlight_max, props='color:white;background-color:gray', axis=1)\n",
    ")\n",
    "display(results)\n",
    "print(f'O melhor modelo é o {winner}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dbe59db-be59-4ca9-add3-24647e97eb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def highlight_max(s, props=''):\n",
    "#     values = [float(value.split()[0]) for value in s.values[1:]]\n",
    "#     result = [''] * len(s.values)\n",
    "#     if s.values[0].endswith('time'):\n",
    "#         result[np.argmin(values)+1] = props\n",
    "#     else:\n",
    "#         result[np.argmax(values)+1] = props\n",
    "#     return result\n",
    "\n",
    "# def get_winner(s):\n",
    "#     metric = s.values[0]\n",
    "#     values = [float(value.split()[0]) for value in s.values[1:]]\n",
    "#     models = results.columns[1:]\n",
    "    \n",
    "#     if s.values[0].endswith('time'):\n",
    "#         return models[np.argmin(values)]\n",
    "#     else:\n",
    "#         return models[np.argmax(values)]\n",
    "\n",
    "# results = (\n",
    "#     pd\n",
    "#     .DataFrame(scores)\n",
    "#     .groupby(['model'])\n",
    "#     .agg([lambda x: f\"{np.mean(x):.3f} ± {np.std(x):.3f}\"])#\n",
    "#     .transpose()\n",
    "#     .reset_index()\n",
    "#     .rename(columns={\"level_0\": \"score\"})\n",
    "#     .drop(columns=\"level_1\")\n",
    "#     # .set_index('score')\n",
    "# )\n",
    "# time_scores = ['fit_time', 'score_time']\n",
    "# winner = results.query('score not in @time_scores').apply(get_winner, axis=1).value_counts().index[0]\n",
    "# results.columns.name = ''\n",
    "# results = (\n",
    "#     results\n",
    "#     .style\n",
    "#     .hide(axis='index')\n",
    "#     .apply(highlight_max, props='color:white;background-color:gray', axis=1)\n",
    "# )\n",
    "# display(results)\n",
    "# print(f'O melhor modelo é o {winner}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f60b98e-1b2a-448a-bf54-809eccac7457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "TypeError: accuracy_score() got an unexpected keyword argument 'average'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "TypeError: accuracy_score() got an unexpected keyword argument 'average'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "TypeError: accuracy_score() got an unexpected keyword argument 'average'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "TypeError: accuracy_score() got an unexpected keyword argument 'average'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "TypeError: accuracy_score() got an unexpected keyword argument 'average'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "TypeError: accuracy_score() got an unexpected keyword argument 'average'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "TypeError: accuracy_score() got an unexpected keyword argument 'average'\n",
      "\n",
      "  warnings.warn(\n",
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n",
      "/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:770: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 761, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 103, in __call__\n",
      "    score = scorer._score(cached_call, estimator, *args, **kwargs)\n",
      "  File \"/home/bcnishi/.cache/pypoetry/virtualenvs/src-n1MWWP9q-py3.8/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "TypeError: accuracy_score() got an unexpected keyword argument 'average'\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# best_model = next(item for item in models if item[\"name\"] == winner)\n",
    "\n",
    "# param_grid = {\n",
    "#     'preprocessing__quantitative__scaler': [StandardScaler(), MinMaxScaler(), RobustScaler()],\n",
    "#     'preprocessing__nominal__encoder': [OneHotEncoder(sparse=False), OrdinalEncoder()],\n",
    "#     'preprocessing__nominal__scaler': [StandardScaler(), MinMaxScaler(), RobustScaler()],\n",
    "#     'preprocessing__quantitative__missing__strategy': ['mean', 'median'],\n",
    "#     **{f\"model__{key}\": value for key, value in best_model['parameters'].items()}\n",
    "# }\n",
    "\n",
    "# approach = Pipeline([\n",
    "#     ('preprocessing', preprocessing),\n",
    "#     ('model', best_model['model'])\n",
    "# ])\n",
    "\n",
    "# gs = RandomizedSearchCV(\n",
    "#     estimator=approach,\n",
    "#     param_distributions=param_grid,\n",
    "#     scoring='accuracy',\n",
    "#     cv=n_splits_cv_gs,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# gs.fit(X, y)\n",
    "\n",
    "# model = gs.best_estimator_\n",
    "# joblib.dump(model, '../models/best_model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
